---
title: "p8105_hw6_yc4198"
author: "Yining Chen"
date: "2022-12-03"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,warning=FALSE,message=FALSE}
library(tidyverse)
library(purrr)
library(modelr)
```

## Question 2

### Data cleaning
```{r,warning=FALSE,message=FALSE}
homicide <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

homicide <- homicide%>%
  janitor::clean_names()%>%
  mutate(city_state=str_c(city, ",",state),
         resolved = as.numeric(disposition == "Closed by arrest"),
         victim_age = as.numeric(victim_age))%>%
  filter(victim_race== "White"|victim_race== "Black")%>%
  filter(city_state != "Dallas,TX"&city_state != "Phoenix,AZ"&city_state != "Kansas City,MO"& city_state != "Tulsa,AL")
```

### Fit the model for Baltimore
```{r}
baltimore <- homicide%>%filter(city_state == "Baltimore,MD")%>%
  mutate(
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_race = fct_relevel(victim_race, "White")) %>% 
  select(resolved, victim_age, victim_race, victim_sex)

glm1 <- glm(resolved ~ victim_age+victim_sex+victim_race, data = baltimore,family = binomial())

glm1 %>% broom::tidy() %>%
  mutate(OR = exp(estimate),
         lower_CI = OR - qnorm(0.95)*std.error,
         upper_CI = OR + qnorm(0.95)*std.error,
         term = str_replace(term, "victim_sex", "Victim Sex: "))%>%
  filter(term == "victim_sexMale")%>%
    select(term, OR, lower_CI,upper_CI)%>%
  knitr::kable(digits = 3)
```

### Run glm for each city
```{r}
each_city = 
  homicide %>%
  select(city_state,resolved, victim_age, victim_race, victim_sex)%>%
  nest(data = -city_state)%>%
  mutate(
    fit  = map(.x = data,  ~glm(resolved ~ victim_race + victim_sex + victim_age, data = .x, family = "binomial")),
    result = map(fit, broom::tidy)) %>%
    unnest(result) %>% 
  filter(term == "victim_sexMale")%>%
    mutate(OR = exp(estimate),
         lower_CI = OR - qnorm(0.95)*std.error,
         upper_CI = OR + qnorm(0.95)*std.error)%>%
    select(city_state, OR, lower_CI,upper_CI)%>%
  knitr::kable(digits = 3)
```

```{r}
each_city%>% 
  ggplot(aes(x=OR,y = reorder(city_state, -OR))) +
  geom_point(color="red",size=1) +
  geom_errorbar(aes(xmin = lower_CI, xmax = upper_CI)) +  
  theme(axis.text.x = element_text(size = 8,vjust = 0.5, hjust = 1),axis.text.y = element_text(size=5.5))+
  ylab("City")+
  xlab("Odds Ratio")+
  ggtitle("Estimated ORs and CIs for each city.")
```
- New York has the lowest odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed which is around 0.25. This means that homicides in which the victim is male are 75% less likely to be resolved that those in which the victim is female in New York.

- Albuquerque has the highest odds ratio for solving homicides comparing male victims to female victims which is around 1.75. This means that homicides in which the victim is male are 75% more likely to be resolved that those in which the victim is female in Albuquerque.

- Most cities have odds ratios less than 1, indicating that homicides in which the victim is male are significantly less like to be resolved than those in which the victim is female in most cities.

## Question 3

### Load and clean the data for regression analysis 
```{r,warning=FALSE,message=FALSE}
birthweight = read_csv("data/birthweight.csv") %>%
  janitor::clean_names()%>%
  drop_na()%>%
 mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace)
  ) 
  
```

### Propose a regression model for birthweight. 

I started with a full model with all 19 variables as explanatory variables and birthweight as the response variable. Then I used a stepwise model selection,which is a combination of forward and backward selections. This is to build regression model from a set of candidate predictor variables by entering and removing predictors based on p values, until there is no variable left to enter or remove any more.
 
The final model includes the following variables:
babysex: baby’s sex (male = 1, female = 2)
bhead: baby’s head circumference at birth (centimeters)
blength: baby’s length at birth (centimeteres)
delwt: mother’s weight at delivery (pounds)
fincome: family monthly income (in hundreds, rounded)
gaweeks: gestational age in weeks
mheight: mother’s height (inches)
mrace: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other)
parity: number of live births prior to this pregnancy
ppwt: mother’s pre-pregnancy weight (pounds)
smoken: average number of cigarettes smoked per day during pregnancy

```{r}
mymod <-lm(bwt ~., data = birthweight)
step.model <- step(mymod,direction = "both") 
step.model%>%broom::tidy()
```

### Diagnostics
```{r}
birthweight %>% 
  add_predictions(step.model) %>% 
  add_residuals(step.model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5,color="red") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = "Residuals vs. Fitted Values"
  )+theme_minimal()
```

### Compare models
```{r}
mod1 <- lm(bwt ~ blength+gaweeks, data = birthweight)
mod2 <- lm(bwt ~ bhead+blength+babysex+bhead*blength+blength*babysex+bhead*babysex+bhead*babysex*blength, data = birthweight)
```

```{r,warning=FALSE}
cv_df =
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    step.model  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    mod1     = map(train, ~lm(bwt ~ blength+gaweeks,, data = .x)),
    mod2  = map(train, ~lm(bwt ~ bhead+blength+babysex+bhead*blength+blength*babysex+bhead*babysex+bhead*babysex*blength, data = as_tibble(.x)))) %>% 
  mutate(
    rmse_step = map2_dbl(step.model, test, ~rmse(model = .x, data = .y)),
    rmse_mod1    = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)),
    rmse_mod2 = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)))
```


```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse,color=model)) + geom_violin()+
  theme_minimal()+
  labs(title="Prediction error distribution for each candidate model.")
```
Based on these results, It is clear that the model we selected using stepwise selection has the lowest RMSE which also indicates a higher prediction accuracy. The model with interaction terms has a slightly higher RMSE and the middle model gas a very high RMSE. It is reasonable since it only uses length at birth and gestational age as predictors.

